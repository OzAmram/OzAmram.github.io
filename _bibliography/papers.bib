---
---

@article{Amram:2025vqw,
    abbr={Sub. to JHEP},
    author = "Amram, Oz and Szewc, Manuel",
    title = "{Data-Driven High-Dimensional Statistical Inference with Generative Models}",
    eprint = "2506.06438",
    archivePrefix = "arXiv",
    primaryClass = "hep-ph",
    reportNumber = "FERMILAB-PUB-25-0380-CMS-PPD",
    month = "6",
    year = "2025"
    reportNumber = "FERMILAB-PUB-25-0247-PPD",
    html = {https://arxiv.org/abs/2506.06438}, 
    journal = "Sub. to JHEP",
    month = "6",
    year = "2025",
    abstract = {
        Crucial to many measurements at the LHC is the use of correlated multi-dimensional information to distinguish rare processes from large backgrounds, which is complicated by the poor modeling of many of the crucial backgrounds in Monte Carlo simulations. In this work, we introduce HI-SIGMA, a method to perform unbinned high-dimensional statistical inference with data-driven background distributions. In contradistinction to many applications of Simulation Based Inference in High Energy Physics, HI-SIGMA relies on generative ML models, rather than classifiers, to learn the signal and background distributions in the high-dimensional space. These ML models allow for efficient, interpretable inference while also incorporating model errors and other sources of systematic uncertainties. We showcase this methodology on a simplified version of a di-Higgs measurement in the bbγγ final state, where the di-photon resonance allows for efficient background interpolation from sidebands into the signal region. We demonstrate that HI-SIGMA provides improved sensitivity as compared to standard classifier-based methods, and that systematic uncertainties can be straightforwardly incorporated by extending methods which have been used for histogram based analyses.
    }
}

@article{Brennan:2025fqy,
    abbr={Sub. to PRD},
    author = "Brennan, Liam and Vami, Tamas Almos and Amram, Oz and Sekhar, Sanjana and Takahashi, Yuta and Moureaux, Louis and Sommerhalder, Manuel and Maksimovic, Petar",
    title = "{Weakly supervised anomaly detection with event-level variables}",
    eprint = "2504.13249",
    archivePrefix = "arXiv",
    primaryClass = "hep-ph",
    reportNumber = "FERMILAB-PUB-25-0247-PPD",
    html = {https://arxiv.org/abs/2504.13249}, 
    journal = "Sub. to PRD",
    month = "4",
    year = "2025",
    abstract = {
        We introduce a new topology for weakly supervised anomaly detection searches, di-object plus X. In this topology, one looks for a resonance decaying to two standard model particles produced in association with other anomalous event activity (X). This additional activity is used for classification. We demonstrate how anomaly detection techniques which have been developed for di-jet searches focusing on jet substructure anomalies can be applied to event-level anomaly detection in this topology. To robustly capture event-level features of multi-particle kinematics, we employ new physically motivated variables derived from the geometric structure of a collision's phase space manifold. As a proof of concept, we explore the application of this approach to several benchmark signals in the di-tau plus X final state. We demonstrate that our anomaly detection approach can reach discovery-level significances for signals that would be missed in a conventional bump-hunt approach.
    }

}

@inproceedings{Amram:2025ulh,
    abbr= "{Contribution to ESPP}",
    author = "Amram, Oz and Cummings, Grace",
    title = "{United States Early Career Researchers in Collider Physics input to the European Strategy for Particle Physics Update}",
    eprint = "2503.22834",
    archivePrefix = "arXiv",
    primaryClass = "hep-ex",
    reportNumber = "FERMILAB-CONF-25-0212-AD",
    html = {https://arxiv.org/abs/2503.22834}, 
    month = "3",
    year = "2025",
    abstract = {
        This document represents a contribution of the United States early career collider physics community to the 2025--2026 update to the European Strategy for Particle Physics. Preferences with regard to different future collider options and R\&D priorities were assessed via a survey. The early career community was defined as anyone who is a graduate student, postdoctoral researcher, untenured faculty member, or research scientist under 40 years of age. In total, 105 participants responded to the survey between February and March 10th, 2025. Questions were formulated primarily to gauge the enthusiasm and preferences for different collider options in line with the recommendations of the United States' P5 report, relevant to the European Strategy Update.
    }

}

@article{CMS-PAS-B2G-24-015,
      abbr={CMS-PAS},
      collaboration = "CMS",
      title         = "{Search for resonances decaying to a Higgs boson in the bb
                       final state and an anomalous jet}",
      institution   = "CERN",
      reportNumber  = "CMS-PAS-B2G-24-015",
      journal = "CMS-PAS-B2G-24-015",
      year          = "2025",
      html           = "https://cds.cern.ch/record/2928202",
      abstract = {
          This note presents an analysis searching for new physics through the process where a new massive particle, X, decays into a Higgs boson and a second particle, Y. The Higgs boson subsequently decays into a pair of b-quarks and the decay products of Y are assumed to produce a non-QCD-like, e.g. anomalous, jet. In the benchmark process, Y decays into W + W − forming one large-area jet. A second benchmark process is also considered, where Y is a hadronically decaying top quark, originating from a vector-like quark decaying into a top quark and a Higgs boson. CMS data recorded at a centre-of-mass energy of 13 TeV in 2016-2018 and corresponding to 138 fb-1 are analysed. In this analysis, the identification of the Y particle is enhanced by computing the anomaly score of its candidate jet using an autoencoder, allowing the simultaneous search for multiple Y decay modes with a single analysis. No significant excesses are observed and upper limits on the signal cross section for various masses of X and Y, at 95\% confidence level, are placed.  }
}

@article{CMS:Lund,
      abbr={CMS-PAS},
      author = "CMS Collaboration",
      collaboration = "CMS",
      title         = "{A new method for correcting the substructure of multi-prong jets using Lund jet plane reweighting in the CMS experiment}",
      institution   = "CERN",
      reportNumber  = "CMS-PAS-JME-23-001",
      journal = "CMS PAS JME-23-001",
      address       = "Geneva",
      year          = "2025",
      html           = "https://cds.cern.ch/record/2924412",
      abstract={
          Many analyses at the CERN LHC employ techniques exploiting the substructure of large-radius jets. These techniques aim to identify large-radius jets originating from heavy resonances produced with high momenta that decay into multiple quarks or gluons. The large momentum of the resonance results in all
N quarks or gluons from the decay being reconstructed into a single jet with an N-prong substructure. Because of shortcomings in the simulation of these jets, substructure observables are typically calibrated using data samples of large-radius jets originating from decays of boosted W bosons or top quarks. However, this approach cannot be readily applied to jets with four or more prongs because no similar proxies exist in the data. This note presents a new technique for correcting the substructure of simulated large-radius jets from multi-prong decays. The data correspond to an integrated luminosity of 138 fb^-1 collected by the CMS experiment between 2016--2018 at a center-of-mass energy of 13 TeV . The technique is based on reclustering the jet constituents into several subjets such that each subjet represents a single prong, and separately correcting the radiation pattern in the Lund jet plane of each subjet using a correction derived from data. The correction procedure improves the agreement between data and simulation in several different substructure observables of multi-prong jets. This technique establishes, for the first time, a robust calibration for the substructure of jets with four or more prongs, enabling their usage in future measurements and searches for new phenomena.
      }
}

@article{CMS:CASE,
    abbr={Rept. Prog. Phys.},
    author = "CMS Collaboration",
    collaboration = "CMS",
    title = "{Model-agnostic search for dijet resonances with anomalous jet substructure in proton-proton collisions at $\sqrt{s}$ = 13 TeV}",
    eprint = "2412.03747",
    archivePrefix = "arXiv",
    year = "2024",
    html = {https://arxiv.org/abs/2412.03747},
    journal = "Rept. Prog. Phys.",
    volume = "88",
    number = "6",
    abstract={
        This paper presents a model-agnostic search for narrow resonances in the dijet final state in the mass range 1.8-6 TeV. The signal is assumed to produce jets with substructure atypical of jets initiated by light quarks or gluons, with minimal additional assumptions. Search regions are obtained by utilizing multivariate machine-learning methods to select jets with anomalous substructure. A collection of complementary anomaly detection methods - based on unsupervised, weakly supervised, and semisupervised algorithms - are used in order to maximize the sensitivity to unknown new physics signatures. These algorithms are applied to data corresponding to an integrated luminosity of 138 fb−1, recorded by the CMS experiment at the LHC, at a center-of-mass energy of 13 TeV. No significant excesses above background expectations are seen. Exclusion limits are derived on the production cross section of benchmark signal models varying in resonance mass, jet mass, and jet substructure. Many of these signatures have not been previously sought, making several of the limits reported on the corresponding benchmark models the first ever. When compared to benchmark inclusive and substructure-based search strategies, the anomaly detection methods are found to significantly enhance the sensitivity to a variety of models.
    }
}

@article{Amram:2024fjg,
    abbr={Sub. to ML Sci. Tech.},
    author = {Amram, Oz and others},
    title = "{Aspen Open Jets: Unlocking LHC Data for Foundation Models in Particle Physics}",
    eprint = "2412.10504",
    archivePrefix = "arXiv",
    primaryClass = "hep-ph",
    reportNumber = "FERMILAB-PUB-24-0941-AD",
    month = "12",
    year = "2024",
    html = {https://arxiv.org/abs/2412.10504},
    abstract = { Foundation models are deep learning models pre-trained on large amounts of data which are capable of generalizing to multiple datasets and/or downstream tasks. This work demonstrates how data collected by the CMS experiment at the Large Hadron Collider can be useful in pre-training foundation models for HEP. Specifically, we introduce the AspenOpenJets dataset, consisting of approximately 180M high pT jets derived from CMS 2016 Open Data. We show how pre-training the OmniJet-α foundation model on AspenOpenJets improves performance on generative tasks with significant domain shift: generating boosted top and QCD jets from the simulated JetClass dataset. In addition to demonstrating the power of pre-training of a jet-based foundation model on actual proton-proton collision data, we provide the ML-ready derived AspenOpenJets dataset for further public use.
    }

}

@article{CMS:LQ,
    abbr={Sub. to JHEP},
    author = "Hayrapetyan, Aram and others",
    collaboration = "CMS",
    title = "{Search for $t$-channel scalar and vector leptoquark exchange in the high-mass dimuon and dielectron spectra in proton-proton collisions at $\sqrt{s}$ = 13 TeV}",
    eprint = "2503.20023",
    archivePrefix = "arXiv",
    primaryClass = "hep-ex",
    reportNumber = "CMS-EXO-22-013, CERN-EP-2024-275",
      reportNumber  = "CMS-PAS-EXO-22-013",
      journal = "CMS PAS",
      year          = "2024",
      html           = "https://cms-results.web.cern.ch/cms-results/public-results/preliminary-results/EXO-22-013/index.html",
      abstract = {A search for t -channel exchange of leptoquarks (LQs) is performed using proton-proton collision data collected at √ s = 13 TeV with the CMS detector at the CERN LHC. The data correspond to an integrated luminosity of 138 fb-1 . The search spans scenarios with scalar and vector LQs that couple up and down quarks to electrons and muons. Dielectron and dimuon final states are considered, with dilepton invariant masses above 500 GeV. The differential distributions of dilepton events are fit to templates built from reweighted samples of simulated standard model events. This method is able to probe higher LQ masses than previous pair-production and single-production searches. Limits are set on LQ-fermion coupling strengths for LQ masses up to 5 TeV. Based on the results, scalar LQs are excluded for masses up to 5 TeV for a coupling strength of 1.2, and vector LQs are excluded for masses up to 5 TeV for a coupling strength of 1.5.
 },
}

@article{Krause:2024avx,
	abbr={Sub. to Rept. Prog. Phys.},
    author = "Krause, Claudius and others",
    title = "{CaloChallenge 2022: A Community Challenge for Fast Calorimeter Simulation}",
    eprint = "2410.21611",
    archivePrefix = "arXiv",
    primaryClass = "cs.LG",
    reportNumber = "HEPHY-ML-24-05, FERMILAB-PUB-24-0728-CMS, TTK-24-43",
    month = "10",
    year = "2024",
    html = {https://arxiv.org/abs/2410.21611},
	abstract = {We present the results of the "Fast Calorimeter Simulation Challenge 2022" - the CaloChallenge. We study state-of-the-art generative models on four calorimeter shower datasets of increasing dimensionality, ranging from a few hundred voxels to a few tens of thousand voxels. The 31 individual submissions span a wide range of current popular generative architectures, including Variational AutoEncoders (VAEs), Generative Adversarial Networks (GANs), Normalizing Flows, Diffusion models, and models based on Conditional Flow Matching. We compare all submissions in terms of quality of generated calorimeter showers, as well as shower generation time and model size. To assess the quality we use a broad range of different metrics including differences in 1-dimensional histograms of observables, KPD/FPD scores, AUCs of binary classifiers, and the log-posterior of a multiclass classifier. The results of the CaloChallenge provide the most complete and comprehensive survey of cutting-edge approaches to calorimeter fast simulation to date. In addition, our work provides a uniquely detailed perspective on the important problem of how to evaluate generative models. As such, the results presented here should be applicable for other domains that use generative AI and require fast and faithful generation of samples in a large phase space.
    }
}



@article{CMS:2022uul,
    abbr={JHEP},
    bibtex_show={true},
    author = "CMS Collaboration",
    collaboration = "CMS",
    title = "{Measurement of the Drell-Yan forward-backward asymmetry at high dilepton masses in proton-proton collisions at $\sqrt{s}$ = 13 TeV}",
    eprint = "2202.12327",
    archivePrefix = {arXiv},
    eid = {arxiv:2202.12327},
    primaryClass = "hep-ex",
    reportNumber = "CMS-SMP-21-002, CERN-EP-2022-013",
    doi = "10.1007/JHEP08(2022)063",
    journal = "JHEP",
    volume = "2022",
    number = "08",
    pages = "063",
    year = "2022",
    html = {https://arxiv.org/abs/2202.12327},
    abstract = {A measurement of the forward-backward asymmetry of pairs of oppositely charged leptons (dimuons and dielectrons) produced by the Drell-Yan process in proton-proton collisions is presented. The data sample corresponds to an integrated luminosity of 138 fb−1 collected with the CMS detector at the LHC at a center-of-mass energy of 13 TeV. The asymmetry is measured as a function of lepton pair mass for masses larger than 170 GeV and compared with standard model predictions. An inclusive measurement across both channels and the full mass range yields an asymmetry of 0.612 ± 0.005 (stat) ± 0.007 (syst). As a test of lepton flavor universality, the difference between the dimuon and dielectron asymmetries is measured as well. No statistically significant deviations from standard model predictions are observed. The measurements are used to set limits on the presence of additional gauge bosons. For a Z' boson in the sequential standard model the observed (expected) 95\% confidence level lower limit on the Z' mass is 4.4 (3.7) TeV.}

}

@article{Amram:2023onf,
    abbr={Phys. Rev. D},
    bibtex_show={true},
    author = "Amram, Oz and Pedro, Kevin",
    title = "{Denoising diffusion models with geometry adaptation for high fidelity calorimeter simulation}",
    eprint = "2308.03876",
    archivePrefix = "arXiv",
    eid = {arxiv:2308.03876},
    primaryClass = "physics.ins-det",
    reportNumber = "FERMILAB-PUB-23-384-CSAID-PPD",
    doi = "10.1103/PhysRevD.108.072014",
    journal = "Phys. Rev. D",
    volume = "108",
    number = "7",
    pages = "072014",
    year = "2023",
    html = {https://arxiv.org/abs/2308.03876},
    abstract = {Simulation is crucial for all aspects of collider data analysis, but the available computing budget in the High Luminosity LHC era will be severely constrained. Generative machine learning models may act as surrogates to replace physics-based full simulation of particle detectors, and diffusion models have recently emerged as the state of the art for other generative tasks. We introduce CaloDiffusion, a denoising diffusion model trained on the public CaloChallenge datasets to generate calorimeter showers. Our algorithm employs 3D cylindrical convolutions, which take advantage of symmetries of the underlying data representation. To handle irregular detector geometries, we augment the diffusion model with a new geometry latent mapping (GLaM) layer to learn forward and reverse transformations to a regular geometry that is suitable for cylindrical convolutions. The showers generated by our approach are nearly indistinguishable from the full simulation, as measured by several different metrics.}

}

@article{Kasieczka:2021xcg,
    abbr={Rept. Prog. Phys.},
    bibtex_show={true},
    author = "Kasieczka, Gregor and others",
    title = "{The LHC Olympics 2020 a community challenge for anomaly detection in high energy physics}",
    eprint = "2101.08320",
    archivePrefix = "arXiv",
    eid = {arxiv:2101.08320},
    primaryClass = "hep-ph",
    doi = "10.1088/1361-6633/ac36b9",
    journal = "Rept. Prog. Phys.",
    volume = "84",
    number = "12",
    pages = "124201",
    year = "2021",
    html = {https://arxiv.org/abs/2101.08320},
    abstract = {A new paradigm for data-driven, model-agnostic new physics searches at colliders is emerging, and aims to leverage recent breakthroughs in anomaly detection and machine learning. In order to develop and benchmark new anomaly detection methods within this framework, it is essential to have standard datasets. To this end, we have created the LHC Olympics 2020, a community challenge accompanied by a set of simulated collider events. Participants in these Olympics have developed their methods using an R&D dataset and then tested them on black boxes: datasets with an unknown anomaly (or not). This paper will review the LHC Olympics 2020 challenge, including an overview of the competition, a description of methods deployed in the competition, lessons learned from the experience, and implications for data analyses with future datasets as well as future colliders.}
      
}


@article{Amram:2020ykb,
    abbr={JHEP},
    bibtex_show={true},
    author = "Amram, Oz and Suarez, Cristina Mantilla",
    title = "{Tag N\textquoteright{} Train: a technique to train improved classifiers on unlabeled data}",
    eprint = "2002.12376",
    archivePrefix = "arXiv",
    primaryClass = "hep-ph",
    doi = "10.1007/JHEP01(2021)153",
    journal = "JHEP",
    volume = "01",
    pages = "153",
    year = "2021",
    html = {https://arxiv.org/abs/2002.12376},
    abstract = {There has been substantial progress in applying machine learning techniques to classification problems in collider and jet physics. But as these techniques grow in sophistication, they are becoming more sensitive to subtle features of jets that may not be well modeled in simulation. Therefore, relying on simulations for training will lead to sub-optimal performance in data, but the lack of true class labels makes it difficult to train on real data. To address this challenge we introduce a new approach, called Tag N' Train (TNT), that can be applied to unlabeled data that has two distinct sub-objects. The technique uses a weak classifier for one of the objects to tag signal-rich and background-rich samples. These samples are then used to train a stronger classifier for the other object. We demonstrate the power of this method by applying it to a dijet resonance search. By starting with autoencoders trained directly on data as the weak classifiers, we use TNT to train substantially improved classifiers. We show that Tag N' Train can be a powerful tool in model-agnostic searches and discuss other potential applications.},

}

@article{Lambrides:2021,
    abbr={ApJ},
       author = {{Lambrides}, Erini and Others},
        title = "{Merger or Not: Accounting for Human Biases in Identifying Galactic Merger Signatures}",
      journal = {The Astrophysical Journal},
         year = {2021},
        month = {09},
       volume = {919},
          doi = {10.3847/1538-4357/ac0fdf},
archivePrefix = {arXiv},
       eprint = {2106.15618},
       html = {https://ui.adsabs.harvard.edu/abs/2021ApJ...919...43L},
       abstract = {
           Significant galaxy mergers throughout cosmic time play a fundamental role in theories of galaxy evolution. The widespread usage of human classifiers to visually assess whether galaxies are in merging systems remains a fundamental component of many morphology studies. Studies that employ human classifiers usually construct a control sample, and rely on the assumption that the bias introduced by using humans will be evenly applied to all samples. In this work, we test this assumption and develop methods to correct for it. Using the standard binomial statistical methods employed in many morphology studies, we find that the merger fraction, error, and the significance of the difference between two samples are dependent on the intrinsic merger fraction of any given sample. We propose a method of quantifying merger biases of individual human classifiers and incorporate these biases into a full probabilistic model to determine the merger fraction and the probability of an individual galaxy being in a merger. Using 14 simulated human responses and accuracies, we are able to correctly label a galaxy as ''merger'' or ''isolated'' to within 1\% of the truth. Using 14 real human responses on a set of realistic mock galaxy simulation snapshots our model is able to recover the pre-coalesced merger fraction to within 10\%. Our method can not only increase the accuracy of studies probing the merger state of galaxies at cosmic noon, but also can be used to construct more accurate training sets in machine learning studies that use human classified data-sets.
       }

}
